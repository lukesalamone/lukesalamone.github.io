<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="">
<meta name="keywords" content=", transformer, attention" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://lukesalamone.github.io/posts/self-attention/" />

<meta property="og:title" content="How does a Transformer Work?"/>
<meta property="og:image" content="https://lukesalamone.github.io/img/covers/transformer-cover.png"/>
<meta property="og:description" content="Check out this interactive demo to learn how the transformer and self-attention work!"/>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-9GBJCJFKED"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-9GBJCJFKED');
</script>


    <title>
        
            A Few Notes on the Transformer :: Luke Salamone&#39;s Blog 
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.5.0/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">



<link rel="stylesheet" href="../../main.8a6383efac6dd742c5d60f7b7fd685e292562affcc27ebd03293f62544a84aed.css">






<meta itemprop="name" content="A Few Notes on the Transformer">
<meta itemprop="description" content="A self-attention block depicted as a neural network.
  In this post I will describe the attention mechanism, commonly used in transformers, a popular neural language architecture. Most of the most well-known large language models of late are based on the transformer architecture. Attention was first described in Attention is All You Need by Vaswani et al.
What is attention? At a high level, attention is a mechanism for neural networks to boost portions of an input which are relevant and ignore those which aren&rsquo;t."><meta itemprop="datePublished" content="2022-11-16T15:24:15-05:00" />
<meta itemprop="dateModified" content="2022-11-16T15:24:15-05:00" />
<meta itemprop="wordCount" content="716"><meta itemprop="image" content="https://lukesalamone.github.io"/>
<meta itemprop="keywords" content="transformer,attention," />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://lukesalamone.github.io"/>

<meta name="twitter:title" content="A Few Notes on the Transformer"/>
<meta name="twitter:description" content="A self-attention block depicted as a neural network.
  In this post I will describe the attention mechanism, commonly used in transformers, a popular neural language architecture. Most of the most well-known large language models of late are based on the transformer architecture. Attention was first described in Attention is All You Need by Vaswani et al.
What is attention? At a high level, attention is a mechanism for neural networks to boost portions of an input which are relevant and ignore those which aren&rsquo;t."/>



    <meta property="og:title" content="A Few Notes on the Transformer" />
<meta property="og:description" content="A self-attention block depicted as a neural network.
  In this post I will describe the attention mechanism, commonly used in transformers, a popular neural language architecture. Most of the most well-known large language models of late are based on the transformer architecture. Attention was first described in Attention is All You Need by Vaswani et al.
What is attention? At a high level, attention is a mechanism for neural networks to boost portions of an input which are relevant and ignore those which aren&rsquo;t." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lukesalamone.github.io/posts/self-attention/" /><meta property="og:image" content="https://lukesalamone.github.io"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-11-16T15:24:15-05:00" />
<meta property="article:modified_time" content="2022-11-16T15:24:15-05:00" /><meta property="og:site_name" content="Luke Salamone&#39;s Blog" />







    <meta property="article:published_time" content="2022-11-16 15:24:15 -0500 -0500" />








    </head>

    <body class="dark-theme">
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="../../" style="text-decoration: none;">
  <div class="logo">
    <div class="logo-holder-dark">
      <img src="../../img/logo.png" alt="Blog Home" />
    </div>
    <div class="logo-holder-light">
      <img src="../../img/logo2.png" alt="Blog Home" />
    </div>
  </div>
</a>


        <span class="header__right">
            
            <div id="header_search">
              <input type="text" placeholder="Search here" />
            </div>
        </span>
    </span>
</header>


            <div class="content">
                
  <main class="post">

    <div class="post-info">
      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock">
          <circle cx="12" cy="12" r="10"></circle>
          <polyline points="12 6 12 12 16 14"></polyline>
        </svg>
        4 minutes

        
      </p>
    </div>

    <article>
      <h1 class="post-title">
        <a href="https://lukesalamone.github.io/posts/self-attention/">A Few Notes on the Transformer</a>
      </h1>

      

      <div class="post-content">
        

<figure><img src="../../img/self-attention.png"
         alt="A self-attention block depicted as a neural network."/><figcaption>
            <p>A self-attention block depicted as a neural network.</p>
        </figcaption>
</figure>


<p>In this post I will describe the attention mechanism, commonly used in transformers, a popular neural language architecture. Most of the most well-known large language models of late are based on the transformer architecture. Attention was first described in <a href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Attention is All You Need</a> by Vaswani et al.</p>

<h2 id="what-is-attention">What is attention?</h2>

<p>At a high level, attention is a mechanism for neural networks to boost portions of an input which are relevant and ignore those which aren&rsquo;t. In language models, attention is used as a way for the model to learn which portions of a sentence are relevant to each word.</p>

<h2 id="what-is-attention-for">What is attention for?</h2>

<p>Let&rsquo;s use an example:</p>

<blockquote>
<p>I am sitting at the library with my friend.</p>
</blockquote>

<p>It should be pretty clear that not all words in this sentence are equally important. What words are relevant to &ldquo;I&rdquo;? Probably &ldquo;sitting&rdquo;, &ldquo;library&rdquo;, and &ldquo;friend&rdquo;. Likewise, &ldquo;the&rdquo; might only be relevant to &ldquo;library&rdquo;. Attention provides a way for a model to increase and decrease the importance of each word.</p>

<p>Since the value of each token in the sequence is dependent on other tokens, this method of generating word embeddings is very different from more classical methods like <a href="https://arxiv.org/pdf/1301.3781.pdf">Word2Vec</a> and <a href="https://nlp.stanford.edu/projects/glove/">GloVe</a>. There is no one fixed vector for a given word.</p>

<p>And this makes sense. Many words in English are homonyms, and have identical spellings for distinct meanings. For example, &ldquo;rock&rdquo; is a genre of music but also can mean a stone. <a href="https://www.npr.org/2011/05/30/136796448/has-run-run-amok-it-has-645-meanings-so-far">The word &ldquo;run&rdquo; has 645 meanings and has recently replaced &ldquo;set&rdquo; as the word with the most definitions.</a> It would not make sense for all of these homonyms to have the same vector.</p>

<h2 id="an-interactive-example">An interactive example</h2>

<p>You can hover over each word to see the relative importances of each word in the sentence to the hovered word.</p>

<p><div id="attention_demo"></div>
<link rel="stylesheet" href="../../css/attention-demo.css" />
<script src="../../js/attention_demo.js"></script></p>

<h2 id="how-does-self-attention-work">How does self-attention work?</h2>

<p><figure><img src="../../img/scaled-dot-prod-attention.png"
         alt="The Vaswani paper describes scaled dot product attention, which involves normalizing by the square root of the input dimension."/><figcaption>
            <p>The Vaswani paper describes scaled dot product attention, which involves normalizing by the square root of the input dimension.</p>
        </figcaption>
</figure>

This is the part where Vaswani delves into a database analogy with <strong>keys</strong>, <strong>queries</strong>, and <strong>values</strong>. Most online resources try to salvage this analogy. Personally, I always found this a bit confusing. What you need to know is that keys, values, and queries correspond to 3 matrices M<sub>k</sub>, M<sub>q</sub>, and M<sub>v</sub>, which are used in a dot product with the original input vectors.</p>

<p>In linear algebra terms this means multiplying the 1xd input vector by a matrix of size dxd. In neural network terms, this means passing the input vector through a full-connected layer. After M<sub>k</sub> and M<sub>q</sub> are multiplied, they are normalized by the square root of d<sub>k</sub>, a constant representing the dimension of the input vector.</p>

<h2 id="can-we-attend-to-multiple-parts-of-a-sentence">Can we attend to multiple parts of a sentence?</h2>

<figure><img src="../../img/multi_head_attention.png"
         alt="Multi-headed attention means performing attention n times in parallel inside of an encoder block."/><figcaption>
            <p>Multi-headed attention means performing attention n times in parallel inside of an encoder block.</p>
        </figcaption>
</figure>


<p>Yes, that is called multi-headed attention. Its architecture is very similar, using  additional M<sub>k</sub>, M<sub>q</sub>, and M<sub>v</sub> matrices for each additional &ldquo;attention head&rdquo;. In the Vaswani paper they used 8 heads.</p>

<h2 id="how-do-transformers-compare-with-other-architectures-e-g-rnn-cnn">How do transformers compare with other architectures (e.g. RNN/CNN)?</h2>

<figure><img src="../../img/attention_performance.png"
         alt="When the input sequence length n is lower than the input dimensionality d, self-attention is faster than recurrent neural networks. Self-attention is also easily parallelizable."/><figcaption>
            <p>When the input sequence length n is lower than the input dimensionality d, self-attention is faster than recurrent neural networks. Self-attention is also easily parallelizable.</p>
        </figcaption>
</figure>


<p>Generally speaking, RNNs are able to memorize but not parallelize, and CNNs are able to parallelize but not memorize. Transformers are able to do both.</p>

<p>The Vaswani paper outlines three main benefits:</p>

<ol>
<li><p>Computational complexity per layer. Self-attention layers are faster than recurrent layers when the input sequence length is smaller than the input vector dimensionality.</p></li>

<li><p>The opportunity to parallelize calculations. Each head in multi-headed attention can be computed separately in an encoder layer.</p></li>

<li><p>Easier to learn long-range dependencies. For many English sentences, especially fairly complex ones found in more scientific writings, the full context of a word cannot be learned from its immediate neighbors. Sometimes it can&rsquo;t even be found in the same sentence. However, even though most language models prior to the transformer had theoretically infinite input sequence lengths, in practice it was quite difficult for them to learn long-range dependencies. Because a transformer sees its whole input simultaneously, Vaswani argues, it is able to more easily learn those dependencies.</p></li>
</ol>

<h2 id="is-that-all">Is that all?</h2>

<p>No. In part two I will describe the encoder and decoder blocks, as well as the self-supervised training process.</p>

      </div>
    </article>

    <hr />

    <div class="post-info">
      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg>

        <span class="tag"><a href="https://lukesalamone.github.io/tags/transformer/">transformer</a></span>
        <span class="tag"><a href="https://lukesalamone.github.io/tags/attention/">attention</a></span>
        
    </p>

      

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
          <line x1="16" y1="13" x2="8" y2="13"></line>
          <line x1="16" y1="17" x2="8" y2="17"></line>
          <polyline points="10 9 9 9 8 9"></polyline>
        </svg>
        716 Words
      </p>

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar">
          <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
          <line x1="16" y1="2" x2="16" y2="6"></line>
          <line x1="8" y1="2" x2="8" y2="6"></line>
          <line x1="3" y1="10" x2="21" y2="10"></line>
        </svg>
        
          2022-11-16 12:24
        

        
          
        
      </p>
    </div>

    
      <div class="pagination">
        <div class="pagination__title">
          <span class="pagination__title-h">Read other posts</span>
          <hr />
        </div>

        <div class="pagination__buttons">
          
            <span class="button previous">
              <a href="https://lukesalamone.github.io/posts/digging-to-china/">
                <span class="button__icon">←</span>
                <span class="button__text">The Other End of the Earth</span>
              </a>
            </span>
          

          
            <span class="button next">
              <a href="https://lukesalamone.github.io/posts/qualitative-analysis-chess/">
                <span class="button__text">A new type of chess tournament</span>
                <span class="button__icon">→</span>
              </a>
            </span>
          
        </div>
      </div>
    


    
  </main>
  <div id="shadow-search" class="posts">
    <div class="posts-group">
      <div class="post-year">2022</div>
      <ul class="posts-list"></ul>
    </div>
  </div>

            </div>

            
                <footer class="footer">
    <div class="footer__inner">
        <div class="footer__content">
            <span>&copy; 2022</span>
            <span><a href="https://lukesalamone.com/" target="_blank">lukesalamone.com</a></span>
            <span>&nbsp;|&nbsp;</span>
            <span><a href="https://github.com/lukesalamone/" target="_blank">github</a></span>
        </div>
    </div>
</footer>

            
        </div>

        




<script type="text/javascript" src="../../bundle.min.6e3c1600024e56e8bc744e9d2307abeb07531c35d8a501e933992234d69d5ac4b89d2a70dbeb88af234d9f7a031494ce781ffeb155e6027abcfd4f10ce80a3f8.js" integrity="sha512-bjwWAAJOVui8dE6dIwer6wdTHDXYpQHpM5kiNNadWsS4nSpw2&#43;uIryNNn3oDFJTOeB/&#43;sVXmAnq8/U8QzoCj&#43;A=="></script>



    </body>
</html>
