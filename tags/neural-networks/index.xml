<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Neural-Networks on Luke Salamone&#39;s Blog</title>
    <link>http://localhost:1313/tags/neural-networks/</link>
    <description>Recent content in Neural-Networks on Luke Salamone&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 07 Mar 2021 01:31:51 -0600</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/neural-networks/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Autoencoding Stock Prices</title>
      <link>http://localhost:1313/posts/build-an-autoencoder/</link>
      <pubDate>Sun, 07 Mar 2021 01:31:51 -0600</pubDate>
      <guid>http://localhost:1313/posts/build-an-autoencoder/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;../../img/autoencoder.png&#34;&#xA;    alt=&#34;Autoencoding stock prices as found in Heaton et al., 2016&#34;&gt;&lt;figcaption&gt;&#xA;      &lt;p&gt;Autoencoding stock prices as found in Heaton et al., 2016&lt;/p&gt;&#xA;    &lt;/figcaption&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;So you want to build an autoencoder? Great! This article will demonstrate how to build an autoencoder and use it to measure stock prices against an index. This technique is described in more technical terms &lt;a href=&#34;https://arxiv.org/pdf/1602.06561.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Once we&amp;rsquo;ve trained the autoencoder, we can use it to measure how well each component follows the other members of the index. This can be useful for finding deeper insights into an index, and doesn&amp;rsquo;t require a priori knowledge of the index price or the weighting of its components. Note, this is only one metric which one could use to determine how well one member of the group follows the group overall. Another might be &lt;a href=&#34;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient&#34;&gt;Pearson Correlation&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Siamese Neural Networks (Video)</title>
      <link>http://localhost:1313/posts/siamese-nn-video/</link>
      <pubDate>Thu, 17 Dec 2020 11:22:43 -0600</pubDate>
      <guid>http://localhost:1313/posts/siamese-nn-video/</guid>
      <description>&lt;div style=&#34;text-align:center&#34;&gt;&#xA;  &lt;iframe src=&#34;https://player.vimeo.com/video/491725663&#34; width=&#34;640&#34; height=&#34;360&#34; frameborder=&#34;0&#34; allow=&#34;autoplay; fullscreen&#34; allowfullscreen&gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;&lt;em&gt;The following is a transcript of the above video&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;In this paper, the authors present a novel neural network architecture to enable audio search via sounds humans are able to make, for example humming and whistling. This is an important capability when searching through audio for a specific sound.&lt;/p&gt;&#xA;&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;&#xA;&lt;p&gt;Imagine you have hundreds of unlabeled sound effects on your computer, and you are looking for a specific one. It could be very tedious to listen to every single one until you can find the right sound. Even if the sounds do have some kind of word labels, it could be hard to pinpoint exactly which words to search for. A lot of sounds donâ€™t exactly lend themselves to text descriptors, so finding the right sound can be difficult with a text search.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
