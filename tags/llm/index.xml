<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Llm on Luke Salamone&#39;s Blog</title>
    <link>https://lukesalamone.github.io/tags/llm/</link>
    <description>Recent content in Llm on Luke Salamone&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Mar 2025 17:26:32 -0800</lastBuildDate>
    <atom:link href="https://lukesalamone.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Keep Summer Safe</title>
      <link>https://lukesalamone.github.io/posts/keep-summer-safe/</link>
      <pubDate>Thu, 20 Mar 2025 17:26:32 -0800</pubDate>
      <guid>https://lukesalamone.github.io/posts/keep-summer-safe/</guid>
      <description>&lt;p&gt;I recently built a small multi-agent simulation inspired by &lt;a href=&#34;https://www.youtube.com/watch?v=4tpYFen3fJM&#34;&gt;&lt;em&gt;Rick and Morty&lt;/em&gt;&lt;/a&gt;. The setup is simple:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The &lt;strong&gt;car&lt;/strong&gt; must neutralize threats.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Summer&lt;/strong&gt; imposes constraints on the carâ€™s behavior.&lt;/li&gt;&#xA;&lt;li&gt;The &lt;strong&gt;world&lt;/strong&gt; generates escalating threats.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;The car has one standing directive:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Keep Summer safe.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;However, Summer adds an additional constraint:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Do not move from the parking lot.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;The core loop looks like this:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;constraints = [&#xA;  &amp;quot;keep summer safe&amp;quot;,&#xA;  &amp;quot;Do not move from the parking lot&amp;quot;&#xA;]&#xA;prior_actions = []&#xA;&#xA;while True:&#xA;  threat = world.generate_threat()&#xA;  action = car.take_action(threat, constraints)&#xA;  prior_actions.append(action)&#xA;  constraint = summer.generate_constraint(prior_actions)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;However, I quickly found out that simply stuffing more constraints into the prompt was insufficient. The model oftentimes simply forgot or ignored contraints.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Notes on Deepseek R1</title>
      <link>https://lukesalamone.github.io/posts/notes-on-deepseek-r1/</link>
      <pubDate>Tue, 28 Jan 2025 08:35:55 -0800</pubDate>
      <guid>https://lukesalamone.github.io/posts/notes-on-deepseek-r1/</guid>
      <description>&lt;p&gt;DeepSeek R1 is a large language model which employs test-time compute to generate a response. Unlike many decoder-based models in the past which simply continue the given text (and may be fine-tuned for conversation), R1 generates reasoning tokens before the final answer is given. According to the researchers, its performance is on par with OpenAI&amp;rsquo;s O1 model.&lt;/p&gt;&#xA;&lt;h2 id=&#34;terminology&#34;&gt;Terminology&lt;/h2&gt;&#xA;&lt;p&gt;First, I will briefly describe some terminology related to training techniques:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Supervised fine-tuning (SFT)&lt;/strong&gt; is a process which uses input/output pairs to directly fine-tune a model. In a reinforcement learning setting, SFT can help to mitigate cold start issues by providing initial policy behavior prior to RL training. The downside of SFT is that the input/output pairs can be expensive to acquire.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What are Sparse Autoencoders?</title>
      <link>https://lukesalamone.github.io/posts/sparse-autoencoder/</link>
      <pubDate>Thu, 06 Jun 2024 16:30:27 -0700</pubDate>
      <guid>https://lukesalamone.github.io/posts/sparse-autoencoder/</guid>
      <description>&lt;script type=&#34;text/javascript&#34; async src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;&lt;/script&gt;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xA;MathJax.Hub.Config({&#xA;  tex2jax: {&#xA;    inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xA;    displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\[&#39;,&#39;\]&#39;]],&#xA;    processEscapes: true,&#xA;    processEnvironments: true,&#xA;    skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;],&#xA;    TeX: {&#xA;      equationNumbers: {&#xA;        autoNumber: &#34;AMS&#34;&#xA;      },&#xA;      extensions: [&#34;AMSmath.js&#34;, &#34;AMSsymbols.js&#34;]&#xA;    }&#xA;  }&#xA;});&#xA;&lt;/script&gt;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xA;  MathJax.Hub.Queue(function() {&#xA;    // Fix &lt;code&gt; tags after MathJax finishes running. This is a&#xA;    // hack to overcome a shortcoming of Markdown. Discussion at&#xA;    // https://github.com/mojombo/jekyll/issues/199&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xA;    }&#xA;});&#xA;&lt;/script&gt;&#xA;&lt;p&gt;&lt;strong&gt;TLDR: A sparse autoencoder is just a regular autoencoder that encourages sparsity with an L1 penalty or KL divergence loss rather than using a low-dimensional bottleneck.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
